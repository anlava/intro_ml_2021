{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 'Afterlife'\n",
    "### Review of basic concepts to pass the course\n",
    "\n",
    "### Important: do not delete any blocks\n",
    "#### But you may add as many as you need.\n",
    "\n",
    "\n",
    "#### About tasks\n",
    "\n",
    "This notebook consists of numerous tasks but please make it look like a whole story: a report with your own code, thoughts and conclusions. In some of these tasks you will have to implement some custom functions, in some of them you will be asked to present some plots and describe them. Please try to make your code as short as possible and your answers as clear as possible (in Russian or English).\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "- There are **Questions** in the tasks, don't skip them. If you skip a question, the whole task is considered as skipped.\n",
    "- When your answer includes some numbers, make sure to provide some code or calculations that prove your results.\n",
    "- Pay a lot attention to your plots:\n",
    "    - Are they comprehensible? Shapes, colours, sizes?\n",
    "    - Are they titled?\n",
    "    - Are axes labelled?\n",
    "    - Is legend included?\n",
    "\n",
    "#### How to submit\n",
    "- Name your file according to this convention: `2021_afterlife_GroupNumber_Surname_Name.ipynb`, for example \n",
    "    - `2021_afterlife_404_Sheipak_Sviat.ipynb`\n",
    "- Attach your .ipynb to an email with topic `2021_afterlife_GroupNumber_Surname_Name.ipynb`\n",
    "- Send it to `cosmic.research.ml@yandex.ru`\n",
    "\n",
    "\n",
    "#### The Data:\n",
    "- All the datasets you need are here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Basic concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.1.**\n",
    "\n",
    "**Q:** What is supervised learning? What is the main goal of supervised learning? What is the difference between classification and regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.2.**\n",
    "\n",
    "**Q:** What are objects and labels in classification and regression? Provide at least three examples of classification and regression tasks. For each of these examples suggest a few features that can be used in this tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.**\n",
    "\n",
    "**Q:** Name as many binary classification quality metrics as you can. Provide a formula for each of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.4.**\n",
    "\n",
    "**Q:** Calculate all the metrics you mentioned in the task above. Implement them, do not import anything apart from `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n",
    "ground_truth = [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
    "\n",
    "# Metric 1:\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Metric 2:\n",
    "# YOUR CODE HERE\n",
    "# ...\n",
    "\n",
    "\n",
    "# Metric N:\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.6.**\n",
    "\n",
    "**Q:** What is ROC-AUC? Present two ways how to calculate it (plot-based and probability based). Implement at least one of this methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [0.8, 0.41, 0.76, 0.6, 0.35, 0.74, 0.54, 0.1, 0.51, 0.68, 0.43, 0.95]\n",
    "ground_truth = [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.7.**\n",
    "\n",
    "**Q:** What are train and test sets? What is the purpose of splitting the data into train and test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.8.**\n",
    "\n",
    "**Q:** What is overfitting? How do you spot overfitting? What are general ways to overcome it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_db = load_iris()\n",
    "iris_db.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.1.**\n",
    "\n",
    "**Q:** What are classes and features in this dataset? For each feature plot a histogram of its distribution. Plot bars for each class with a separate colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.2.**\n",
    "Let's consider only two features and two classes: sepal length and sepal width and setosa and versicolor. Plot a 2D scatterplot, each class with its colour and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.3.**\n",
    "\n",
    "Using a dataset from 2.2 train 4 decison trees of depths `[1, 2, 3, 4]`.\n",
    "\n",
    "For each tree examine classification metrics, plot decision boundaries [[tips]]((https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_decision_regions.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.4.**\n",
    "\n",
    "- Using a dataset from 2.2 train a linear model and linear SVM.\n",
    "- Plot decision boundaries for these models and print accuracies.\n",
    "- What are analytical formulas for these boundaries?\n",
    "- What is the difference between these two models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.1.**\n",
    "\n",
    "**Q:** What are hyperapameters of a ML-model? What differs them from internal parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download the breast cancer dataset. Split it into train and test (70% train and 30% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_db = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = bc_db.data, bc_db.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.1.** \n",
    "\n",
    "Explain what is K-fold cross-validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.2.** \n",
    "\n",
    "Explain how RF is formed up from decision trees for regression and classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.3.**\n",
    "\n",
    "- Run a 2D grid search for RF\n",
    "- Measure training time of each iteration of the search\n",
    "- Suggest a few ways to make the whole search faster\n",
    "- Apply one of these faster methods and compare conusmed time and classification quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.4.** \n",
    "\n",
    "Try to beat a RF with non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.5.** \n",
    "\n",
    "Tune a voting classifier over SVM and RF, report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Basic text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First task is about binary classification of words: we'll try to separate russian surnames from common russian words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(filename, prefix=\"\"):\n",
    "    res = []\n",
    "    with open(prefix + filename, \"r\") as input_file:\n",
    "        for line in input_file.readlines():\n",
    "            res.append(line.strip())\n",
    "    return res\n",
    "\n",
    "surnames = np.array(read_list_from_file(\"data/russian_surnames.txt\"))\n",
    "all_words = np.array(read_list_from_file(\"data/russian.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames_labels = np.ones_like(surnames, dtype=int)\n",
    "allwords_labels = np.zeros_like(all_words, dtype=int)\n",
    "\n",
    "X = np.concatenate([surnames, all_words])\n",
    "y = np.concatenate([surnames_labels, allwords_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.1.** \n",
    "\n",
    "We are going to use syllables as features. Why this idea can be reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.** \n",
    "\n",
    "Implement a simple tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_word(word, token_len=3):\n",
    "    ''' Function that splits word into sequence of tokens\n",
    "    Args:\n",
    "        word (string): input word\n",
    "        token_len (int): length of each token\n",
    "    Returns:\n",
    "        list(str): list of tokens \n",
    "    '''\n",
    "    tokens_list = []\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return tokens_list\n",
    "\n",
    "assert tokenize_word(\"cybersnatch\") == ['cyb', 'ybe', 'ber', 'ers', 'rsn', 'sna', 'nat', 'atc', 'tch'], \"smth's wrong\"\n",
    "print(\"tokenize_word: seems legit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3.** Feature extraction:\n",
    "\n",
    "- Apply tokenizer to each word to split it into 3-char syllables\n",
    "- Map list of tokens to a vector with CountVectorizer\n",
    "- Map list of tokens to a vector with HashingVectorizer\n",
    "- Train Linear Model and RF on each of these datasets (don't forget to split (X,y) into train and test)\n",
    "- Report the results (training time and f1): which model is better and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.1.** \n",
    "\n",
    "What is clustering? What is the difference between clustering and multiclass classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.2.** \n",
    "\n",
    "What is K-means? How it works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.3.** Iris + Kmeans\n",
    "\n",
    "Apply K-means to Iris dataset. Plot clustering result on a 2D plane for each pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.4.** PCA\n",
    "\n",
    "- What is mathematical concept behind PCA\n",
    "- What can be main purposes of PCA usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.5.** \n",
    "\n",
    "Plot clustering you've obtained above on a 2D plane using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
